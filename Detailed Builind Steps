申明：
1 主机和节点机器的username要一致，本文用：erqi
2 主机的hostname：master
  节点机器的hostname分别为：slave1，slave2

#################################################################################################################
jdk:
sudo wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" 
http://download.oracle.com/otn-pub/java/jdk/8u144-b01/090f390dda5b47b9b721c7dfaa008135/jdk-8u144-linux-x64.tar.gz

hadoop:(最好下载最新版本)
wget http://apache.mirrors.tds.net/hadoop/common/hadoop-2.8.1/hadoop-2.8.1.tar.gz

#################################################################################################################
1 配置java环境
  1.1 将jdk-8u144-linux-x64.gz 和hadoop-2.8.1.tar.gz 拷贝到3台虚拟机的一个文件夹中，解压。
  
  1.2 构造jvm
      sudo mkdir /usr/lib/jvm
      sudo cp -r ./jdk1.8.0_144 /usr/lib/jvm/
  
  1.3 添加环境变量
      sudo vim /etc/profile #原文为：sudo gedit /etc/profile
       文末添加：
        export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_144
        export JRE_HOME=${JAVA_HOME}/jre
        export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
        export PATH=${JAVA_HOME}/bin:$PATH
  
  1.4 使环境变量生效
      source /etc/profile
  
  1.5 查看java版本
      java –version


2 ssh安装以及配置(有了ssh，可借助WinSCP或putty登陆虚拟机文件系统)
  2.1 更新apt
      sudo apt-get update
  
  2.2 安装ssh
      sudo apt-get install openssh-server
      查看ssh：ps -e | grep ssh

  2.3 验证ssh是否成功安装
      ssh localhost
  
  2.4 生成密钥
      ssh-keygen -t rsa (一直回车即可)
  
  2.5 实现mater对slave1, slave2的无密码登陆
      将mater的公钥拷贝至/home/erqi：cp .ssh/id_rsa.pub ~/id_rsa_master.pub
      将master的id_rsa_master.pub拷到至slave1,slave2的home/erqi下：scp ~/id_rsa_master.pub:erqi@slave_ip:~/
      将master的id_rsa_master.pub写入slave的密钥中：cat id_rsa_master.pub >> .ssh/authorized_keys


3 配置Hadoop (master中进行)
  3.1 在hadoop-2.8.1目录中新建必要文件夹
      mkdir hadoop-2.8.1/tmp
      mkdir hadoop-2.8.1/hdfs
      mkdir hadoop-2.8.1/hdfs/name
      mkdir hadoop-2.8.1/hdfs/data
  
  3.2 修改host (master和slave中都要进行)
      (若仅在master中进行容易出现java.net.UnknownHostException: slave2: slave2: Temporary failure in name resolution )
      sudo vim /etc/hosts
      注释掉所有内容，写入：
        master_ip master
        slave1_ip slave1
        slave2_ip slave2
        (ip可由ifconfig指令查看)
  
  3.3 主机和节点机器各自修改hostname (master和slave中都要进行)
      sudo vim /etc/hostname
      各自将“localhost”修改为master、slave1、slave2
  
  3.4 修改环境变量(为方便集群搜寻，master_ip以具体ip地址代替) (master中进行)
     3.4.1 hadoop-env.sh
           vim etc/hadoop/hadoop-env.sh
           找到JAVA_HOME=行修改为: export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_65
     3.4.2 core-site.xml
           vim etc/hadoop/core-site.xml
           在configuration标签中添加
             <property>
                 <name>fs.defaultFS</name>
                 <value>hdfs://master_ip:9000</value>
             </property>
             <property>
                 <name>hadoop.tmp.dir</name>
                 <value>file:/home/erqi/hadoop-2.8.1/tmp</value>
             </property>
     3.4.3 mapred-site.xml
           cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml
           vim etc/hadoop/mapred-site.xml
           在configuration标签中添加
             <property>
                 <name>fs.defaultFS</name>
                 <value>hdfs://master_ip:9000</value>
             </property>
             <property>
                 <name>hadoop.tmp.dir</name>
                 <value>file:/home/erqi/hadoop-2.8.1/tmp</value>
             </property>  
     3.4.4 hdfs-site.xml
           vim etc/hadoop/hdfs-site.xml
           在configuration标签中添加
             <property>
                 <name>dfs.namenode.name.dir</name>
                 <value>file:/home/erqi/hadoop-2.8.1/hdfs/name</value>
             </property>
             <property>
                 <name>dfs.datanode.data.dir</name>
                 <value>file:/home/erqi/hadoop-2.8.1/hdfs/data</value>
             </property>
             <property>
                 <name>dfs.replication</name>
                 <value>2</value> (此处2为节点机器数量)
             </property>
             <property>
                 <name>dfs.namenode.secondary.http-address</name>
                 <value>master_ip:9001</value>
             </property>
     3.4.5 yarn-site.xml
           vim etc/hadoop/yarn-site.xml
           在configuration标签中添加
             <property>
                 <name>yarn.nodemanager.aux-services</name>
                 <value>mapreduce_shuffle</value>
             </property>
             <property>
                 <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
                 <value>org.apache.hadoop.mapred.ShuffleHandler</value>
             </property>
             <property>
                 <name>yarn.resourcemanager.address</name>
                 <value>master_ip:8032</value>
             </property>
             <property>
                 <name>yarn.resourcemanager.scheduler.address</name>
                 <value>master_ip:8030</value>
             </property>
             <property>
                 <name>yarn.resourcemanager.resource-tracker.address</name>
                 <value>master_ip:8031</value>
             </property>
             <property>
                 <name>yarn.resourcemanager.admin.address</name>
                 <value>master_ip:8033</value>
             </property>
             <property>
                 <name>yarn.resourcemanager.webapp.address</name>
                 <value>master_ip:8088</value>
             </property>
     3.4.6 slaves文件
           vim etc/hadoop/slaves1
           删除原有内容"localhost",写入
             slave1
             slave2

  3.5 分发配置好的hadoop文件夹到slave1, slave2 (master中进行)
      scp -r ~/hadoop-2.8.1 erqi@slave1:~/ 
      scp -r ~/hadoop-2.8.1 erqi@slave2:~/ 

  3.6 格式化hdfs (master中进行)
      cd hadoop-2.8.1
      bin/hdfs namenode -format

  3.7 启动集群 (master中进行)
      sbin/start-all.sh (可用jps查看进程)

  3.8 测试集群 (master中进行)
      3.8.1 进入hadoop home目录：cd hadoop-2.8.1 
      3.8.2 在hdfs中创建一个名为input的文件夹: bin/hadoop fs –mkdir /input
            查看文件是否被创建: bin/hadoop fs –ls /
      3.8.3 在本地创建inputfile文件夹，并创建两个文件
            mkdir inputfile
            echo "hello hadoop" >> inputfile/1.txt
            echo "hello world" >> inputfile/2.txt
      3.8.4 上传两个文件进input: bin/hadoop fs -put inputfiles/*.txt /input
            查看输入文件是否传入: bin/hadoop fs -ls /input
      3.8.5 用hadoop jar命令运行Hadoop自带的wordcount
            bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar wordcount /input /output1
      3.8.6 程序运行成功后查看输出文件夹: bin/hadoop fs -ls /output
      3.8.7 查看结果: bin/hadoop fs -cat /output/part-r-00000

#################################################################################################################
###############################************************WARNING************************###########################
#################################################################################################################
1 一般情况下namenode只需要format一次；
2 若多次format namenode，则需要
  2.1 保持master上的hdfs/name/current/VERSION和slave上的hdfs/data/current/VERSION文件中ClusterID一致；
  2.2 解决方法: 
      (1) 修改master上的ClusterID，再重新启动集群；
      (2) 逐一修改 (或删除) slave上的ClusterID (与slave上的ClusterID一致)，再重新启动集群；
